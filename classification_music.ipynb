{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Pour le dataframe\n",
    "import numpy as np # Pour la normalisation et calculs de moyenne\n",
    "import matplotlib.pyplot as plt # Pour la visualisation\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import librosa # Pour l'extraction des features et la lecture des fichiers wav\n",
    "import librosa.display # Pour récupérer les spectrogrammes des audio\n",
    "import librosa.feature\n",
    "\n",
    "import os # C'est ce qui va nous permettre d'itérer sur les fichiers de l'environnement de travail\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, validation_curve, RandomizedSearchCV # Split de dataset et optimisation des hyperparamètres\n",
    "from sklearn.ensemble import RandomForestClassifier # Random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # XGBoost\n",
    "from sklearn.neighbors import KNeighborsClassifier # k-NN\n",
    "from sklearn.svm import SVC # SVM\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, f1_score, zero_one_loss, classification_report # Métriques pour la mesure de performances\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "\n",
    "import tensorflow as tf # Pour le reseau de neurones simple et pour le CNN\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voici la liste des genres musicaux représentés dans la notre base de données, on en compte 10.\n",
    "genres = ['blues', 'classical', 'country', 'disco', 'hiphop', \n",
    "          'jazz', 'metal', 'pop', 'reggae', 'rock']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#On commence par initialiser le dictionnaire avec les clés qui sont les noms des genres.\n",
    "#On met autant de listes vides qu'il n'y a de genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un dictionnaire vide pour stocker les données audio pour chaque genre\n",
    "audio_files = {}\n",
    "\n",
    "# Itérer sur la liste des genres\n",
    "for g in genres:\n",
    "    # Créer une liste vide pour stocker les données audio pour le genre actuel\n",
    "    audio_files[g] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: './genres/rock'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Itérer sur les fichiers audio dans le répertoire pour le genre actuel\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfor\u001b[39;00m audio \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./genres/\u001b[39;49m\u001b[39m{\u001b[39;49;00mg\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m):\n\u001b[0;32m      3\u001b[0m     \u001b[39m# Charger les données audio en utilisant librosa et les ajouter à la liste pour le genre actuel\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     audio_data \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mload(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./genres/\u001b[39m\u001b[39m{\u001b[39;00mg\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00maudio\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m     audio_files[g]\u001b[39m.\u001b[39mappend(audio_data)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: './genres/rock'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Itérer sur les fichiers audio dans le répertoire pour le genre actuel\n",
    "for audio in os.listdir(f'./Data/genres_original/{g}'):\n",
    "    # Charger les données audio en utilisant librosa et les ajouter à la liste pour le genre actuel\n",
    "    audio_data = librosa.load(f'./Data/genres_original/{g}/{audio}')[0]\n",
    "    audio_files[g].append(audio_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons présentés toutes les features que l'on a considéré, construisons un pipeline pour créer une base d'apprentissage.\\\n",
    "Toutes ces features sont facilement calculables avec la librairie Python Librosa.\\\n",
    "_Ce pipeline nous servira aussi pour essayer nos modèles sur des fichiers musicaux externes (YouTube par exemple)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_pipeline(audio):\n",
    "  \n",
    "  features = []\n",
    "\n",
    "  # Calcul du ZCR\n",
    "\n",
    "  zcr = librosa.zero_crossings(audio)\n",
    "  features.append(sum(zcr))\n",
    "\n",
    "  # Calcul de la moyenne du Spectral centroid\n",
    "\n",
    "  spectral_centroids = librosa.feature.spectral_centroid(audio)[0]\n",
    "  features.append(np.mean(spectral_centroids))\n",
    "  \n",
    "  # Calcul du spectral rolloff point\n",
    "\n",
    "  rolloff = librosa.feature.spectral_rolloff(audio)\n",
    "  features.append(np.mean(rolloff))\n",
    "\n",
    "  # Calcul des moyennes des MFCC\n",
    "\n",
    "  mfcc = librosa.feature.mfcc(audio)\n",
    "\n",
    "  for x in mfcc:\n",
    "    features.append(np.mean(x))\n",
    "\n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On écrit les noms des features dans les colonnes d'un dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['zcr', 'spectral_c', 'rolloff', 'mfcc1', 'mfcc2', 'mfcc3',\n",
    "                'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9',\n",
    "                'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15',\n",
    "                'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for g in genres:\n",
    "  for music in audio_files[g]:\n",
    "    df.loc[i] = audio_pipeline(music)+[g]\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
