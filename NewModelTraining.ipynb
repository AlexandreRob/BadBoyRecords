{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Pour le dataframe\n",
    "from skimage.transform import resize\n",
    "import numpy as np # Pour la normalisation et calculs de moyenne\n",
    "import matplotlib.pyplot as plt # Pour la visualisation\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import librosa # Pour l'extraction des features et la lecture des fichiers wav\n",
    "import librosa.display # Pour récupérer les spectrogrammes des audio\n",
    "import librosa.feature\n",
    "\n",
    "import os # C'est ce qui va nous permettre d'itérer sur les fichiers de l'environnement de travail\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, validation_curve, RandomizedSearchCV # Split de dataset et optimisation des hyperparamètres\n",
    "from sklearn.ensemble import RandomForestClassifier # Random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # XGBoost\n",
    "from sklearn.neighbors import KNeighborsClassifier # k-NN\n",
    "from sklearn.svm import SVC # SVM\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, f1_score, zero_one_loss, classification_report # Métriques pour la mesure de performances\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "\n",
    "import tensorflow as tf # Pour le reseau de neurones simple et pour le CNN\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/1Mdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Afficher le total de titres par genres :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_titles_counts = df['genres'].value_counts()\n",
    "print(genre_titles_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compter les genres uniques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genres_count = df['genres'].nunique()\n",
    "print(f\"Number of unique genres: {unique_genres_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identification des genres minoritaires :\n",
    "    Identifiez les genres qui ont un nombre très faible de titres. Vous pouvez fixer un seuil en dessous duquel les genres seront considérés comme trop minoritaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 500  # Seuil\n",
    "genre_counts = df['genres'].value_counts()\n",
    "minority_genres = genre_counts[genre_counts <= threshold].index\n",
    "print(minority_genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quelles sont les implications concernant ce résultat ?\n",
    "**1. Distribution très déséquilibrée :**\n",
    "Notre ensemble de données est très déséquilibré, avec quelques genres très bien représentés et une grande majorité de genres avec peu de titres.\n",
    "\n",
    "**2. Risque de surapprentissage :**\n",
    "Avec une telle distribution, il y a un risque élevé que notre modèle soit biaisé en faveur des genres bien représentés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2000  # Seuil\n",
    "genre_counts = df['genres'].value_counts()\n",
    "to_remove = genre_counts[genre_counts <= threshold].index\n",
    "df = df[~df['genres'].isin(to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genres_count = df['genres'].nunique()\n",
    "print(f\"Number of unique genres after operation: {unique_genres_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Résultats après le tri\n",
    "**1. Réduction significative :**\n",
    "Nous avons considérablement réduit le nombre de genres, ce qui devrait faciliter l'entraînement du modèle et améliorer sa généralisation.\n",
    "\n",
    "**2. Focus sur les genres populaires :**\n",
    "Avec seulement 26 genres restants, votre modèle sera très axé sur les genres les plus populaires ou les plus couramment représentés dans notre ensemble de données.\n",
    "\n",
    "**3. Risque de perte d'information :**\n",
    "Il est important de noter que cette approche pourrait entraîner la perte d'informations sur les genres moins courants, ce qui pourrait être pertinent selon l'objectif de notre projet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Affichage des genres restants, ainsi que du nombre de titres par genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_genres = df['genres'].unique()\n",
    "print(\"Remaining genres after applying the threshold:\")\n",
    "print(remaining_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_genre_counts = df['genres'].value_counts()\n",
    "print(\"Remaining genres and their counts after applying the threshold:\")\n",
    "print(remaining_genre_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Equilibrage des classes :\n",
    "**Sous-échantillonnage :**\n",
    "Nous pouvons réduire le nombre d'échantillons des classes sur-représentées pour les équilibrer avec les classes moins représentées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre d'échantillons à conserver pour la classe \"Rock\"\n",
    "n_samples_rock = 60000  # Vous pouvez ajuster ce nombre selon vos besoins\n",
    "\n",
    "# Séparer les données de la classe \"Rock\" et des autres classes\n",
    "df_rock = df[df['genres'] == 'Rock']\n",
    "df_other = df[df['genres'] != 'Rock']\n",
    "\n",
    "# Sous-échantillonnage de la classe \"Rock\"\n",
    "df_rock_sampled = df_rock.sample(n=n_samples_rock, random_state=1)\n",
    "\n",
    "# Fusionner les données sous-échantillonnées de \"Rock\" avec les autres données\n",
    "df_balanced = pd.concat([df_rock_sampled, df_other])\n",
    "\n",
    "# Vérifier la nouvelle distribution des classes\n",
    "new_genre_counts = df_balanced['genres'].value_counts()\n",
    "print(\"New genre distribution:\")\n",
    "print(new_genre_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supprimer \"Soundtrack\" :**\n",
    "Étant donné que \"Soundtrack\" peut être un mélange de différents genres et styles, il peut être difficile pour le modèle de le classer de manière significative. Le supprimer pourrait simplifier le problème de classification.\n",
    "\n",
    "**Fusionner \"Other\" et \"Easy Listening\" :**\n",
    "Si \"Other\" est une catégorie fourre-tout et que \"Easy Listening\" est un genre moins représenté, les fusionner peut aider à équilibrer les classes tout en réduisant le nombre de catégories à prédire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les lignes où le genre est \"Soundtrack\"\n",
    "df_balanced = df_balanced[df_balanced['genres'] != 'Soundtrack']\n",
    "\n",
    "# Fusionner les genres \"Other\" et \"Easy Listening\" en une seule catégorie \"Other/Easy Listening\"\n",
    "df_balanced['genres'] = df_balanced['genres'].apply(lambda x: 'Other/Easy Listening' if x in ['Other', 'Easy Listening'] else x)\n",
    "\n",
    "# Vérifier la nouvelle distribution des genres\n",
    "new_genre_counts = df_balanced['genres'].value_counts()\n",
    "print(\"New genre distribution after adjustments:\")\n",
    "print(new_genre_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mainteanant que notre CSV à l'air relativement exploitable, nous allons le sauvegarder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrer le DataFrame dans un nouveau fichier CSV\n",
    "df_balanced.to_csv('balanced_genre_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/balanced_genre_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genres_count = df['genres'].nunique()\n",
    "print(f\"Number of unique genres after operation: {unique_genres_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création du modèle IA de forêts aléatoires avec sklearn\n",
    "Les forêts aléatoires sont un excellent choix pour un modèle basé sur des métadonnées. Ce sont des modèles d'ensemble qui sont généralement bien adaptés pour gérer des jeux de données de grande dimension et des caractéristiques hétérogènes. Ils sont également moins sensibles au surajustement par rapport à un arbre de décision unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Data/balanced_genre_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['genres', 'track_id', 'song_id'], axis=1)  # Supprimer les colonnes inutiles à l'entraînement du modèle\n",
    "y = data['genres']  # Utiliser la colonne des genres comme étiquettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Créer le modèle de forêt aléatoire\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entraîner le modèle\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Faire des prédictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Évaluer le modèle\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test d'un modèle de classification à travers un Réseau de Neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Créer le modèle de réseau de neurones\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=300, learning_rate_init=0.001)\n",
    "\n",
    "# Entraîner le modèle\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Faire des prédictions\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Évaluer le modèle\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Utilisation de la validation croisée\n",
    "scores = cross_val_score(mlp, X, y, cv=5)\n",
    "print(\"Cross-Validation Scores: \", scores)\n",
    "print(\"Mean Cross-Validation Score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calcul de la matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Affichage de la matrice de confusion\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cbar=False)\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.xlabel(\"Prédiction\")\n",
    "plt.ylabel(\"Vérité\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commme nous pouvons le voir, les scores ne sont pas convaiquants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement du modèle\n",
    "filename = 'BadBoyModelV2.sav'\n",
    "pickle.dump(mlp, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(loaded_model.score(X_test, y_test), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous n'avons pas de pistes pour exploiter le modèle et faire une prédiction avec ce dernier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions :\n",
    "- Il n'est pas possible de faire des prédictions avec un tel modèle\n",
    "- Le modèle manque de précision dû au fait qu'il a été entrainé sur des métadonnées et non des données riches venant de fichiers audios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Axes d'Améliorations : \n",
    "- Télécharger plusieurs datasets de [fichiers audios](https://music-classification.github.io/tutorial/part2_basics/dataset.html), les regrouper et entrainer le modèle sur ces derniers au lieu de se baser sur des **csv**\n",
    "- Faire une prédiction sur le spectrogramme obtenu du fichier audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Points à voir pour la V3\n",
    "1. Vérification de la qualité des données fournies\n",
    "2. Poids des données (si possible)\n",
    "3. Ré-entraînement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
